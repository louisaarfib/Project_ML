{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to classify ?\n",
    "\n",
    "Lecture 3 : we saw the KNN algorithm to classify samples into classes. \n",
    "\n",
    "In our dataset, several electronic devices consume power. Each device is part of a category of devices :  \n",
    "-multimedia = [computer, 3D_printer, internet_router, laptop, phone_charger, printer, screen, tv, sound_system],  \n",
    "-kitchen = [boiler, coffee, freezer, fridge, micro_wave_oven],  \n",
    "-cooling = [air_conditioner, fan],  \n",
    "-other = [air_purifier, dehumidifier, radiator, solar_panel, vacuum].\n",
    "\n",
    "Each category might have similar features, which could permit us to classify an unknown device. For example, in the category \"washing\", we expect all devices to be consuming power mainly during off-peak time, about once a week.\n",
    "\n",
    "1-DIVIDE BY WEEKS EACH DEVICE so we get more data. Start on Monday at 00:00:01 for each device, each week. Create new files (save) so we don't have to compute the code all the time\n",
    "\n",
    "2-Compute relevant components  \n",
    "Try to plot each component for each class to see if we can already see some differences between the classes, see if the components are relevant. Plot boxplot\n",
    "\n",
    "3-Create X and Y : use the \"plug_name\" of the file \"0_smart_plugs...\"  \n",
    "\n",
    "4- KNN on all the components (multiple dimensions KNN, more than  2 dim). Rescale\n",
    "For the KNN : plot the accuracy, the graphs for different values of neighbors (see Lecture 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Relevant components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-maximum power\n",
    "-time of use\n",
    "-period of use\n",
    "-used during the night or not\n",
    "-number of times used during a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes device file and extract the relevant components\n",
    "def components(file_device):\n",
    "    \"function that takes the 0_smart_plugs_devices.csv and the device file and extract the relevant components\"\n",
    "    \"file device : path to the file, ex : household_power_consumption/solar_panel_325.csv\"\n",
    "    \n",
    "    f_0=\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- KNN and classification\n",
    "\n",
    "We now have the components that can distinguish two classes of devices. We perform the KNN algorithm to classify the devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Simple knn\n",
    "\n",
    "\"X array of the form np.array([[x11,x12,x13,x14],...,[x_40_1,x_40_2,_40_3,_40_4]]) if 40 devices and 4 componenets to class them\"\n",
    "\"Y array of the form np.array([y1,...,y40]) if 40 devices and 4 components to class them, with y1,...y40 is an int to indicate to which class the device belongs\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"accuracy: {:.2f}\".format(knn.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "#Influence of number of neighbors\n",
    "#If two major components : can plot the 2d-classification with a different number of neighbors\n",
    "#Can choose two components to represent it once\n",
    "\n",
    "def plot_2d_classification(classifier, X, fill=False, ax=None, eps=None, alpha=1):                                       \n",
    "    # multiclass                                                                                                                 \n",
    "    if eps is None:\n",
    "        eps = X.std() / 2.                                                                                                       \n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()                                                                                                           \n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - eps, X[:, 0].max() + eps                                                                      \n",
    "    y_min, y_max = X[:, 1].min() - eps, X[:, 1].max() + eps                                                                      \n",
    "    xx = np.linspace(x_min, x_max, 1000)                                                                                         \n",
    "    yy = np.linspace(y_min, y_max, 1000)                                                                                         \n",
    "\n",
    "    X1, X2 = np.meshgrid(xx, yy)                                                                                                 \n",
    "    X_grid = np.c_[X1.ravel(), X2.ravel()]                                                                                       \n",
    "    decision_values = classifier.predict(X_grid)                                                                                 \n",
    "    ax.imshow(decision_values.reshape(X1.shape), extent=(x_min, x_max,                                                           \n",
    "                                                       y_min, y_max),                                                          \n",
    "            aspect='auto', origin='lower', alpha=alpha)                                                               \n",
    "    ax.set_xlim(x_min, x_max)                                                                                                    \n",
    "    ax.set_ylim(y_min, y_max)                                                                                                    \n",
    "    ax.set_xticks(())                                                                                                            \n",
    "    ax.set_yticks(())\n",
    "    \n",
    "fig, axes = plt.subplots(2, 2, figsize=(4, 4))\n",
    "for ax, n_neighbors in zip(axes.ravel(), [2, 5, 10, 50]):\n",
    "    ax.set_title(\"n_neighbors={}\".format(n_neighbors))\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X, y)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k')\n",
    "    plot_2d_classification(clf, X, ax=ax, alpha=.5)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    \n",
    "#Model complexity\n",
    "\n",
    "neighbors = range(1, 30, 2)\n",
    "\n",
    "training_scores = []\n",
    "test_scores = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)\n",
    "\n",
    "for n_neighbors in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X_train, y_train)\n",
    "    training_scores.append(knn.score(X_train, y_train))\n",
    "    test_scores.append(knn.score(X_test, y_test))\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(neighbors, training_scores, label=\"training scores\")\n",
    "plt.plot(neighbors, test_scores, label=\"test scores\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#Improving the results : Cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "cross_val_scores = []\n",
    "\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "    cross_val_scores.append(np.mean(scores))\n",
    "    \n",
    "print(\"best cross-validation score: {:.3f}\".format(np.max(cross_val_scores)))\n",
    "best_n_neighbors = neighbors[np.argmax(cross_val_scores)]\n",
    "print(\"best n_neighbors:\", best_n_neighbors)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"test-set score: {:.3f}\".format(knn.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "#Improving again the complexity of the model : GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "param_grid_knn = {'n_neighbors': np.arange(1, 15, 2)}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid_knn,\n",
    "                    cv=10, return_train_score=True)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "print(\"test-set score: {:.3f}\".format(grid.score(X_test, y_test)))\n",
    "\n",
    "import pandas as pd\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "print(results)\n",
    "\n",
    "#ploting the results\n",
    "\n",
    "results.plot('param_n_neighbors', 'mean_test_score', ax=plt.gca())\n",
    "plt.fill_between(results.param_n_neighbors.astype(int),\n",
    "                 results['mean_train_score'] + results['std_train_score'],\n",
    "                 results['mean_train_score'] - results['std_train_score'], alpha=0.2)\n",
    "plt.fill_between(results.param_n_neighbors.astype(int),\n",
    "                 results['mean_test_score'] + results['std_test_score'],\n",
    "                 results['mean_test_score'] - results['std_test_score'], alpha=0.2)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
